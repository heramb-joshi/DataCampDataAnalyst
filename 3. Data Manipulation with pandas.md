# Introducing DataFrames
## DataFrames
>**Pandas is based on NumPy and Matplotlib packages**
- In pandas, the rectangular data is stored as dataFrame object
- Every column in the dataFrame contain the same data type but different column can contain different data types

>**Ways of Exploring the data frame**
- .head() - display first five rows of the dataFrame
- .info() - displays names of columns, the data type and whether it has any missing columns
- .shape  - displays the dimension of the dataset into (rows, columns). Note that, this is an attribute and not a method hence the paranthesis is not required
- .describe() - computes some summary statstics for the columns. Provides quick overview of the numeric clumns
> Dataframes consists of three components, accessible through attributes
- .values - contains the data values reprenseted in 2D- NumPy array 1 array for each row 
- .columns - contains columns names
- .index - contains row numbers or row names

>**Exapmle - Pandas Dataset exploration**
```python
# Print the head of the homelessness data
print(homelessness.head())

# Print information about homelessness
print(homelessness.info())

# Print the shape of homelessness
print(homelessness.shape)

# Print a description of homelessness
print(homelessness.describe())

# Import pandas using the alias pd
import pandas as pd

# Print the values of homelessness
print(homelessness.values)

# Print the column index of homelessness
print(homelessness.columns)

# Print the row index of homelessness
print(homelessness.index)
```

## Sorting and Subsetting
### Sorting

>**Changing order of rows by sorting**
```python
df.sort_values("column_name") #Will sort datafrmae in the ascending order
df.sort_values("column_name", ascending=Fales) # Will sort int the descending order

# We can sort by multiple variables by passing them as a list
df.sort_values(["column_name1","column_name2"])
#while we need to sort order to be different, pass a list of bollenasto asending paramerters
df.sort_values(["column_name1","column_name2"], ascending = [True, False])
```

### Subsetting
>**Subsetting can be done or rows or columns**

#### Subsetting Columns

>**We may want to zoom in to just a few columns or multiple**
```python
df["column_name"] #displays the content of only 1 column
df[["column_name1","column_name2"]] # Displaying multiple columns, pass the list of column names

# You can provide a seperate list of columns as a variable and then perform subsetting

cols_to_subset = ["column_name1","column_name2"]
df[cols_to_subset]

```
#### Subsetting rows

>**We may want to zoom in to just a few rows or multiple**

```python
df["columns_name"] > value # Returns a boolean. Use this logical condition inside []
df[df["column_name"] > value]
```

>**Subsetting based on text data**
```python
df[df["column_name"] == "value"]
```
>**subsetting based on dates**
```python
df[df["date_column_name"] < "2015-01-01"]
```
>**subsetting based on multiple conditions using logical operators**
```python
is_lab = dogs["breed"] == "Labrador"
is_brown = dogs["color"] == "Brown"
dogs[is_lab & is_brown]

# this can be done in one line of code**

dogs[(dogs["breed"] == "Labrador") & (dogs["color"] == "Brown")]
```
>**Subsetting using.isin()**
```python
is_black_or_brown = dogs["color"].isin(["Black","Brown"])
dogs[is_black_or_brown]
```

>**Exapmle Sorting and Subsetting**
```python
# Sort homelessness by individuals
homelessness_ind = homelessness.sort_values("individuals")

# Print the top few rows
print(homelessness_ind.head())

#########
# Sort homelessness by descending family members
homelessness_fam = homelessness.sort_values("family_members" , ascending = False)

# Print the top few rows
print(homelessness_fam.head())

#########
# Sort homelessness by region, then descending family members
homelessness_reg_fam = homelessness.sort_values(["region", "family_members"], ascending=[True, False])

# Print the top few rows
print(homelessness_reg_fam.head())

#######################
# Select the individuals column
individuals = homelessness["individuals"]

# Print the head of the result
print(individuals.head())

#########
# Select the state and family_members columns
state_fam = homelessness[["state","family_members"]]

# Print the head of the result
print(state_fam.head())

#########
# Select only the individuals and state columns, in that order
ind_state = homelessness[["individuals","state"]]

# Print the head of the result
print(ind_state.head())

################ Filtering rows
# Filter for rows where individuals is greater than 10000
ind_gt_10k = homelessness[homelessness["individuals"] > 10000]

# See the result
print(ind_gt_10k)

#########
# Filter for rows where region is Mountain
mountain_reg = homelessness[homelessness["region"] == "Mountain"]

# See the result
print(mountain_reg)

#########
# Filter for rows where family_members is less than 1000 
# and region is Pacific
fam_lt_1k_pac = homelessness[(homelessness["family_members"] < 1000) & (homelessness["region"] == "Pacific")]

# See the result
print(fam_lt_1k_pac)


#########
# Subset for rows in South Atlantic or Mid-Atlantic regions
south_mid_atlantic = homelessness[homelessness["region"].isin(["South Atlantic", "Mid-Atlantic"])]

# See the result
print(south_mid_atlantic)

#####
# The Mojave Desert states
canu = ["California", "Arizona", "Nevada", "Utah"]

# Filter for rows in the Mojave Desert states
mojave_homelessness = homelessness[homelessness["state"].isin(canu)]

# See the result
print(mojave_homelessness)
```
## New Columns
### Adding New Columns
>**syntax**
>df["new_column_name"] = df["old_column_name"] with some calculation

```python
dogs["bmi"] = dogs["weight_kg"] / dogs["height_m"] ** 2
```
>**Exapmle:- Adding new columns**
```python
# Add total col as sum of individuals and family_members
homelessness["total"] = homelessness["individuals"] + homelessness["family_members"]

# Add p_individuals col as proportion of total that are individuals
homelessness["p_individuals"] = homelessness["individuals"] / homelessness["total"]

# See the result
print(homelessness)

##############
# Create indiv_per_10k col as homeless individuals per 10k state pop
homelessness["indiv_per_10k"] = 10000 * homelessness["individuals"] / homelessness["state_pop"] 

# Subset rows for indiv_per_10k greater than 20
high_homelessness = homelessness[homelessness["indiv_per_10k"] > 20]

# Sort high_homelessness by descending indiv_per_10k
high_homelessness_srt = high_homelessness.sort_values("indiv_per_10k", ascending = False)

# From high_homelessness_srt, select the state and indiv_per_10k cols
result = high_homelessness_srt[["state", "indiv_per_10k"]]

# See the result
print(result)
```
# Summary Stattistics - Aggregating the data

## Summarizing the numerical data
- .mean() to identify the center of your data
- .median(), .mode()
- .min(), .max()
- .var(), .std()
- .sum()
- .quantile()

## Summarizing the Date columns
- similar methods as of numerical data
```python
dogs["date_birth"].min() # Oldest dog
dogs["date_birth"].max() # Youngest dog
```
- .agg() #or aggregate method allows us to compute custom summart statistics
```python
def pct30(column):
  return column.quantile(0.3)
  
dogs["weight_kg"].agg(pct30) #calculates 30th percentil of the dogs weight
```
>**Agg can be used for more than one columns**
```python
dogs[["weight_kg","height_cm"]].agg(pct30)
```

>**We can pass multiple custom summaries as well**
```python
def pct40(column):
  return column.quantile(0.4)
  
dogs["weight_kg"].agg([pct30, pct40])

```
>**Cumulative statistics - return entire column of the dataframe rather than just one summary number**
- Cumulative sum using the method .cumsum()

```python
dogs["weight_kg"].cumsum()
```
- .cummax()
- .cummin()
- .cumprod()

>**Examples - Mean and median**
```python

# Print the head of the sales DataFrame
print(sales.head())

# Print the info about the sales DataFrame
print(sales.info())

# Print the mean of weekly_sales
print(sales["weekly_sales"].mean())

# Print the median of weekly_sales
print(sales["weekly_sales"].median())

```

>**Example - Summarizing the dates**
```python
# Print the maximum of the date column
print(sales["date"].max())

# Print the minimum of the date column
print(sales["date"].min())
```
>**Exapmle - Efficient Summaries**
```python
# A custom IQR function
def iqr(column):
    return column.quantile(0.75) - column.quantile(0.25)
    
# Print IQR of the temperature_c column
print(sales["temperature_c"].agg(iqr))

>> Output
16.583333333333336

# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment
print(sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg(iqr))

>> Output
temperature_c           16.583
fuel_price_usd_per_l     0.073
unemployment             0.565
dtype: float64

# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment
print(sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg([iqr, np.median]))

>> Output
        temperature_c  fuel_price_usd_per_l  unemployment
iqr            16.583                 0.073         0.565
median         16.967                 0.743         8.099
```

>**Example - Cumulative Statistics**
```python
# Sort sales_1_1 by date
sales_1_1 = sales_1_1.sort_values("date")

# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col
sales_1_1["cum_weekly_sales"] = sales_1_1["weekly_sales"].cumsum()

# Get the cumulative max of weekly_sales, add as cum_max_sales col
sales_1_1["cum_max_sales"] = sales_1_1["weekly_sales"].cummax()

# See the columns you calculated
print(sales_1_1[["date", "weekly_sales", "cum_weekly_sales", "cum_max_sales"]])

>> Output
            date  weekly_sales  cum_weekly_sales  cum_max_sales
0     2010-02-05      24924.50         2.492e+04       24924.50
1894  2010-02-05      21654.54         4.658e+04       24924.50
4271  2010-02-05     232558.51         2.791e+05      232558.51
4283  2010-02-05      56702.80         3.358e+05      232558.51
4296  2010-02-05         12.00         3.359e+05      232558.51
...          ...           ...               ...            ...
```
## Counting - Summarizing categorical data

>**Removing duplicates**
```python
vet_visits.drop_duplicates(subset = "name") # Removes dogs records with duplicate names
#THis might remove records with same dog names. So need to add more columns for identifying duplicates
vet_visits.drop_duplicates(subset = ["name", "breed"]) #Pass a list of column names to subset arguments

```
>**Count values**
```
unique_dogs["breed"].value_counts()
#We can also sort based on count values
unique_dogs["breed"].value_counts(sort= True)
unique_dogs["breed"].value_counts(normalize= True) #Used to convert counts into proportions of the total
```
> **Example - Dropping Duplicates**
```python
# Drop duplicate store/type combinations
store_types = sales.drop_duplicates(subset = ["store", "type"])
print(store_types.head())

>> Output
      store type  department       date  weekly_sales  is_holiday  temperature_c  fuel_price_usd_per_l  unemployment
0         1    A           1 2010-02-05      24924.50       False          5.728                 0.679         8.106
901       2    A           1 2010-02-05      35034.06       False          4.550                 0.679         8.324
1798      4    A           1 2010-02-05      38724.42       False          6.533                 0.686         8.623
2699      6    A           1 2010-02-05      25619.00       False          4.683                 0.679         7.259
3593     10    B           1 2010-02-05      40212.84       False         12.411                 0.782         9.765

# Drop duplicate store/department combinations
store_depts = sales.drop_duplicates(subset = ["store", "department"])
print(store_depts.head())

>> Output
    store type  department       date  weekly_sales  is_holiday  temperature_c  fuel_price_usd_per_l  unemployment
0       1    A           1 2010-02-05      24924.50       False          5.728                 0.679         8.106
12      1    A           2 2010-02-05      50605.27       False          5.728                 0.679         8.106
24      1    A           3 2010-02-05      13740.12       False          5.728                 0.679         8.106
36      1    A           4 2010-02-05      39954.04       False          5.728                 0.679         8.106
48      1    A           5 2010-02-05      32229.38       False          5.728                 0.679         8.106

# Subset the rows where is_holiday is True and drop duplicate dates
holiday_dates = sales[sales["is_holiday"] == True].drop_duplicates(subset="date")

# Print date col of holiday_dates
print(holiday_dates)

>> Output
      store type  department       date  weekly_sales  is_holiday  temperature_c  fuel_price_usd_per_l  unemployment
498       1    A          45 2010-09-10         11.47        True         25.939                 0.678         7.787
691       1    A          77 2011-11-25       1431.00        True         15.633                 0.855         7.866
2315      4    A          47 2010-02-12        498.00        True         -1.756                 0.680         8.623
6735     19    A          39 2012-09-07         13.41        True         22.333                 1.077         8.193
6810     19    A          47 2010-12-31       -449.00        True         -1.861                 0.881         8.067
6815     19    A          47 2012-02-10         15.00        True          0.339                 1.011         7.943
6820     19    A          48 2011-09-09        197.00        True         20.156                 1.038         7.806

```

>**Example - Counting categorical variables**
```python
# Count the number of stores of each type
store_counts = store_types["type"].value_counts()
print(store_counts)

>> Output
A    11
B     1
Name: type, dtype: int64

# Get the proportion of stores of each type
store_props = store_types["type"].value_counts(normalize = True)
print(store_props)

>> Output
A    0.917
B    0.083
Name: type, dtype: float64

# Count the number of each department number and sort
dept_counts_sorted = store_depts["department"].value_counts(sort = True)
print(dept_counts_sorted)

>> Output
1     12
55    12
72    12
71    12
67    12
      ..
37    10
48     8
50     6
39     4
43     2
Name: department, Length: 80, dtype: int64

# Get the proportion of departments of each number and sort
dept_props_sorted = store_depts["department"].value_counts(sort=True, normalize=True)
print(dept_props_sorted)

>> Output
1     0.013
55    0.013
72    0.013
71    0.013
67    0.013
      ...  
37    0.011
48    0.009
50    0.006
39    0.004
43    0.002
Name: department, Length: 80, dtype: float64
```

## Grouped Summary Statistics

>**Summaries by Groups**
```python
dogs[dogs["color"] == "Black"]["weight_kg"].mean()
dogs[dogs["color"] == "Brown"]["weight_kg"].mean()
dogs[dogs["color"] == "White"]["weight_kg"].mean()
dogs[dogs["color"] == "Gray"]["weight_kg"].mean()
dogs[dogs["color"] == "Tan"]["weight_kg"].mean()

#Instead of writing code multiple times, groupBy method can be used
dogs.groupby("color)["weight_kg"].mean()
```

>**Multiple Summaries by groups**
```python
dogs.groupby("color")["weight_kg"].agg([min, max, sum])
```

>**Grouping by multiple variables**
```python
dogs.groupby(["color","breed"])["weight_kg"].mean()
```

>**Group by and aggregate by multiple columns**
```python
dogs.groupby(["color","breed"])[["weight_kg", "height_cm"]].mean()
```

>**Example - Subset and then add**
```python
# Calc total weekly sales
sales_all = sales["weekly_sales"].sum()
print(sales_all)

# Subset for type A stores, calc total weekly sales
sales_A = sales[sales["type"] == "A"]["weekly_sales"].sum()
print(sales_A)

# Subset for type B stores, calc total weekly sales
sales_B = sales[sales["type"] == "B"]["weekly_sales"].sum()

# Subset for type C stores, calc total weekly sales
sales_C = sales[sales["type"] == "C"]["weekly_sales"].sum()

# Get proportion for each type
sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all
print(sales_propn_by_type)

>> Output
256894718.89999998
233716315.01
[0.9097747 0.0902253 0.       ]
```

>**Example 2 - Calculations with GroupBy()**
```
# Group by type; calc total weekly sales
sales_by_type = sales.groupby("type")["weekly_sales"].sum()
print(sales_by_type)
# Get proportion for each type
sales_propn_by_type = sales_by_type / sum(sales_by_type)
print(sales_propn_by_type)

>> Output
type
A    2.337e+08
B    2.318e+07
Name: weekly_sales, dtype: float64

type
A    0.91
B    0.09
Name: weekly_sales, dtype: float64
```

>**Example3 - Multiple groupings**
```python
# From previous step
sales_by_type = sales.groupby("type")["weekly_sales"].sum()

# Group by type and is_holiday; calc total weekly sales
sales_by_type_is_holiday = sales.groupby(["type","is_holiday"])["weekly_sales"].sum()
print(sales_by_type_is_holiday)

>> Output
type  is_holiday
A     False         2.337e+08
      True          2.360e+04
B     False         2.318e+07
      True          1.621e+03
Name: weekly_sales, dtype: float64
```

# Introducing DataFrames
## DataFrames
>**Pandas is based on NumPy and Matplotlib packages**
- In pandas, the rectangular data is stored as dataFrame object
- Every column in the dataFrame contain the same data type but different column can contain different data types

>**Ways of Exploring the data frame**
- .head() - display first five rows of the dataFrame
- .info() - displays names of columns, the data type and whether it has any missing columns
- .shape  - displays the dimension of the dataset into (rows, columns). Note that, this is an attribute and not a method hence the paranthesis is not required
- .describe() - computes some summary statstics for the columns. Provides quick overview of the numeric clumns
> Dataframes consists of three components, accessible through attributes
- .values - contains the data values reprenseted in 2D- NumPy array 1 array for each row 
- .columns - contains columns names
- .index - contains row numbers or row names

>**Exapmle - Pandas Dataset exploration**
```python
# Print the head of the homelessness data
print(homelessness.head())

# Print information about homelessness
print(homelessness.info())

# Print the shape of homelessness
print(homelessness.shape)

# Print a description of homelessness
print(homelessness.describe())

# Import pandas using the alias pd
import pandas as pd

# Print the values of homelessness
print(homelessness.values)

# Print the column index of homelessness
print(homelessness.columns)

# Print the row index of homelessness
print(homelessness.index)
```

## Sorting and Subsetting
### Sorting

>**Changing order of rows by sorting**
```python
df.sort_values("column_name") #Will sort datafrmae in the ascending order
df.sort_values("column_name", ascending=Fales) # Will sort int the descending order

# We can sort by multiple variables by passing them as a list
df.sort_values(["column_name1","column_name2"])
#while we need to sort order to be different, pass a list of bollenasto asending paramerters
df.sort_values(["column_name1","column_name2"], ascending = [True, False])
```

### Subsetting
>**Subsetting can be done or rows or columns**

#### Subsetting Columns

>**We may want to zoom in to just a few columns or multiple**
```python
df["column_name"] #displays the content of only 1 column
df[["column_name1","column_name2"]] # Displaying multiple columns, pass the list of column names

# You can provide a seperate list of columns as a variable and then perform subsetting

cols_to_subset = ["column_name1","column_name2"]
df[cols_to_subset]

```
#### Subsetting rows

>**We may want to zoom in to just a few rows or multiple**

```python
df["columns_name"] > value # Returns a boolean. Use this logical condition inside []
df[df["column_name"] > value]
```

>**Subsetting based on text data**
```python
df[df["column_name"] == "value"]
```
>**subsetting based on dates**
```python
df[df["date_column_name"] < "2015-01-01"]
```
>**subsetting based on multiple conditions using logical operators**
```python
is_lab = dogs["breed"] == "Labrador"
is_brown = dogs["color"] == "Brown"
dogs[is_lab & is_brown]

# this can be done in one line of code**

dogs[(dogs["breed"] == "Labrador") & (dogs["color"] == "Brown")]
```
>**Subsetting using.isin()**
```python
is_black_or_brown = dogs["color"].isin(["Black","Brown"])
dogs[is_black_or_brown]
```

>**Exapmle Sorting and Subsetting**
```python
# Sort homelessness by individuals
homelessness_ind = homelessness.sort_values("individuals")

# Print the top few rows
print(homelessness_ind.head())

#########
# Sort homelessness by descending family members
homelessness_fam = homelessness.sort_values("family_members" , ascending = False)

# Print the top few rows
print(homelessness_fam.head())

#########
# Sort homelessness by region, then descending family members
homelessness_reg_fam = homelessness.sort_values(["region", "family_members"], ascending=[True, False])

# Print the top few rows
print(homelessness_reg_fam.head())

#######################
# Select the individuals column
individuals = homelessness["individuals"]

# Print the head of the result
print(individuals.head())

#########
# Select the state and family_members columns
state_fam = homelessness[["state","family_members"]]

# Print the head of the result
print(state_fam.head())

#########
# Select only the individuals and state columns, in that order
ind_state = homelessness[["individuals","state"]]

# Print the head of the result
print(ind_state.head())

################ Filtering rows
# Filter for rows where individuals is greater than 10000
ind_gt_10k = homelessness[homelessness["individuals"] > 10000]

# See the result
print(ind_gt_10k)

#########
# Filter for rows where region is Mountain
mountain_reg = homelessness[homelessness["region"] == "Mountain"]

# See the result
print(mountain_reg)

#########
# Filter for rows where family_members is less than 1000 
# and region is Pacific
fam_lt_1k_pac = homelessness[(homelessness["family_members"] < 1000) & (homelessness["region"] == "Pacific")]

# See the result
print(fam_lt_1k_pac)


#########
# Subset for rows in South Atlantic or Mid-Atlantic regions
south_mid_atlantic = homelessness[homelessness["region"].isin(["South Atlantic", "Mid-Atlantic"])]

# See the result
print(south_mid_atlantic)

#####
# The Mojave Desert states
canu = ["California", "Arizona", "Nevada", "Utah"]

# Filter for rows in the Mojave Desert states
mojave_homelessness = homelessness[homelessness["state"].isin(canu)]

# See the result
print(mojave_homelessness)
```
## New Columns
### Adding New Columns
>**syntax**
>df["new_column_name"] = df["old_column_name"] with some calculation

```python
dogs["bmi"] = dogs["weight_kg"] / dogs["height_m"] ** 2
```
>**Exapmle:- Adding new columns**
```python
# Add total col as sum of individuals and family_members
homelessness["total"] = homelessness["individuals"] + homelessness["family_members"]

# Add p_individuals col as proportion of total that are individuals
homelessness["p_individuals"] = homelessness["individuals"] / homelessness["total"]

# See the result
print(homelessness)

##############
# Create indiv_per_10k col as homeless individuals per 10k state pop
homelessness["indiv_per_10k"] = 10000 * homelessness["individuals"] / homelessness["state_pop"] 

# Subset rows for indiv_per_10k greater than 20
high_homelessness = homelessness[homelessness["indiv_per_10k"] > 20]

# Sort high_homelessness by descending indiv_per_10k
high_homelessness_srt = high_homelessness.sort_values("indiv_per_10k", ascending = False)

# From high_homelessness_srt, select the state and indiv_per_10k cols
result = high_homelessness_srt[["state", "indiv_per_10k"]]

# See the result
print(result)
```
# Summary Stattistics - Aggregating the data

## Summarizing the numerical data
- .mean() to identify the center of your data
- .median(), .mode()
- .min(), .max()
- .var(), .std()
- .sum()
- .quantile()

## Summarizing the Date columns
- similar methods as of numerical data
```python
dogs["date_birth"].min() # Oldest dog
dogs["date_birth"].max() # Youngest dog
```
- .agg() #or aggregate method allows us to compute custom summart statistics
```python
def pct30(column):
  return column.quantile(0.3)
  
dogs["weight_kg"].agg(pct30) #calculates 30th percentil of the dogs weight
```
>**Agg can be used for more than one columns**
```python
dogs[["weight_kg","height_cm"]].agg(pct30)
```

>**We can pass multiple custom summaries as well**
```python
def pct40(column):
  return column.quantile(0.4)
  
dogs["weight_kg"].agg([pct30, pct40])

```
>**Cumulative statistics - return entire column of the dataframe rather than just one summary number**
- Cumulative sum using the method .cumsum()

```python
dogs["weight_kg"].cumsum()
```
- .cummax()
- .cummin()
- .cumprod()

>**Examples - Mean and median**
```python

# Print the head of the sales DataFrame
print(sales.head())

# Print the info about the sales DataFrame
print(sales.info())

# Print the mean of weekly_sales
print(sales["weekly_sales"].mean())

# Print the median of weekly_sales
print(sales["weekly_sales"].median())

```

>**Example - Summarizing the dates**
```python
# Print the maximum of the date column
print(sales["date"].max())

# Print the minimum of the date column
print(sales["date"].min())
```
>**Exapmle - Efficient Summaries**
```python
# A custom IQR function
def iqr(column):
    return column.quantile(0.75) - column.quantile(0.25)
    
# Print IQR of the temperature_c column
print(sales["temperature_c"].agg(iqr))

>> Output
16.583333333333336

# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment
print(sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg(iqr))

>> Output
temperature_c           16.583
fuel_price_usd_per_l     0.073
unemployment             0.565
dtype: float64

# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment
print(sales[["temperature_c", "fuel_price_usd_per_l", "unemployment"]].agg([iqr, np.median]))

>> Output
        temperature_c  fuel_price_usd_per_l  unemployment
iqr            16.583                 0.073         0.565
median         16.967                 0.743         8.099
```

>**Example - Cumulative Statistics**
```python
# Sort sales_1_1 by date
sales_1_1 = sales_1_1.sort_values("date")

# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col
sales_1_1["cum_weekly_sales"] = sales_1_1["weekly_sales"].cumsum()

# Get the cumulative max of weekly_sales, add as cum_max_sales col
sales_1_1["cum_max_sales"] = sales_1_1["weekly_sales"].cummax()

# See the columns you calculated
print(sales_1_1[["date", "weekly_sales", "cum_weekly_sales", "cum_max_sales"]])

>> Output
            date  weekly_sales  cum_weekly_sales  cum_max_sales
0     2010-02-05      24924.50         2.492e+04       24924.50
1894  2010-02-05      21654.54         4.658e+04       24924.50
4271  2010-02-05     232558.51         2.791e+05      232558.51
4283  2010-02-05      56702.80         3.358e+05      232558.51
4296  2010-02-05         12.00         3.359e+05      232558.51
...          ...           ...               ...            ...
```
## Counting - Summarizing categorical data

>**Removing duplicates**
```python
vet_visits.drop_duplicates(subset = "name") # Removes dogs records with duplicate names
#THis might remove records with same dog names. So need to add more columns for identifying duplicates
vet_visits.drop_duplicates(subset = ["name", "breed"]) #Pass a list of column names to subset arguments

```
>**Count values**
```
unique_dogs["breed"].value_counts()
#We can also sort based on count values
unique_dogs["breed"].value_counts(sort= True)
unique_dogs["breed"].value_counts(normalize= True) #Used to convert counts into proportions of the total
```
> **Example - Dropping Duplicates**
```python
# Drop duplicate store/type combinations
store_types = sales.drop_duplicates(subset = ["store", "type"])
print(store_types.head())

>> Output
      store type  department       date  weekly_sales  is_holiday  temperature_c  fuel_price_usd_per_l  unemployment
0         1    A           1 2010-02-05      24924.50       False          5.728                 0.679         8.106
901       2    A           1 2010-02-05      35034.06       False          4.550                 0.679         8.324
1798      4    A           1 2010-02-05      38724.42       False          6.533                 0.686         8.623
2699      6    A           1 2010-02-05      25619.00       False          4.683                 0.679         7.259
3593     10    B           1 2010-02-05      40212.84       False         12.411                 0.782         9.765

# Drop duplicate store/department combinations
store_depts = sales.drop_duplicates(subset = ["store", "department"])
print(store_depts.head())

>> Output
    store type  department       date  weekly_sales  is_holiday  temperature_c  fuel_price_usd_per_l  unemployment
0       1    A           1 2010-02-05      24924.50       False          5.728                 0.679         8.106
12      1    A           2 2010-02-05      50605.27       False          5.728                 0.679         8.106
24      1    A           3 2010-02-05      13740.12       False          5.728                 0.679         8.106
36      1    A           4 2010-02-05      39954.04       False          5.728                 0.679         8.106
48      1    A           5 2010-02-05      32229.38       False          5.728                 0.679         8.106

# Subset the rows where is_holiday is True and drop duplicate dates
holiday_dates = sales[sales["is_holiday"] == True].drop_duplicates(subset="date")

# Print date col of holiday_dates
print(holiday_dates)

>> Output
      store type  department       date  weekly_sales  is_holiday  temperature_c  fuel_price_usd_per_l  unemployment
498       1    A          45 2010-09-10         11.47        True         25.939                 0.678         7.787
691       1    A          77 2011-11-25       1431.00        True         15.633                 0.855         7.866
2315      4    A          47 2010-02-12        498.00        True         -1.756                 0.680         8.623
6735     19    A          39 2012-09-07         13.41        True         22.333                 1.077         8.193
6810     19    A          47 2010-12-31       -449.00        True         -1.861                 0.881         8.067
6815     19    A          47 2012-02-10         15.00        True          0.339                 1.011         7.943
6820     19    A          48 2011-09-09        197.00        True         20.156                 1.038         7.806

```

>**Example - Counting categorical variables**
```python
# Count the number of stores of each type
store_counts = store_types["type"].value_counts()
print(store_counts)

>> Output
A    11
B     1
Name: type, dtype: int64

# Get the proportion of stores of each type
store_props = store_types["type"].value_counts(normalize = True)
print(store_props)

>> Output
A    0.917
B    0.083
Name: type, dtype: float64

# Count the number of each department number and sort
dept_counts_sorted = store_depts["department"].value_counts(sort = True)
print(dept_counts_sorted)

>> Output
1     12
55    12
72    12
71    12
67    12
      ..
37    10
48     8
50     6
39     4
43     2
Name: department, Length: 80, dtype: int64

# Get the proportion of departments of each number and sort
dept_props_sorted = store_depts["department"].value_counts(sort=True, normalize=True)
print(dept_props_sorted)

>> Output
1     0.013
55    0.013
72    0.013
71    0.013
67    0.013
      ...  
37    0.011
48    0.009
50    0.006
39    0.004
43    0.002
Name: department, Length: 80, dtype: float64
```

## Grouped Summary Statistics

>**Summaries by Groups**
```python
dogs[dogs["color"] == "Black"]["weight_kg"].mean()
dogs[dogs["color"] == "Brown"]["weight_kg"].mean()
dogs[dogs["color"] == "White"]["weight_kg"].mean()
dogs[dogs["color"] == "Gray"]["weight_kg"].mean()
dogs[dogs["color"] == "Tan"]["weight_kg"].mean()

#Instead of writing code multiple times, groupBy method can be used
dogs.groupby("color)["weight_kg"].mean()
```

>**Multiple Summaries by groups**
```python
dogs.groupby("color")["weight_kg"].agg([min, max, sum])
```

>**Grouping by multiple variables**
```python
dogs.groupby(["color","breed"])["weight_kg"].mean()
```

>**Group by and aggregate by multiple columns**
```python
dogs.groupby(["color","breed"])[["weight_kg", "height_cm"]].mean()
```

>**Example - Subset and then add**
```python
# Calc total weekly sales
sales_all = sales["weekly_sales"].sum()
print(sales_all)

# Subset for type A stores, calc total weekly sales
sales_A = sales[sales["type"] == "A"]["weekly_sales"].sum()
print(sales_A)

# Subset for type B stores, calc total weekly sales
sales_B = sales[sales["type"] == "B"]["weekly_sales"].sum()

# Subset for type C stores, calc total weekly sales
sales_C = sales[sales["type"] == "C"]["weekly_sales"].sum()

# Get proportion for each type
sales_propn_by_type = [sales_A, sales_B, sales_C] / sales_all
print(sales_propn_by_type)

>> Output
256894718.89999998
233716315.01
[0.9097747 0.0902253 0.       ]
```

>**Example 2 - Calculations with GroupBy()**
```
# Group by type; calc total weekly sales
sales_by_type = sales.groupby("type")["weekly_sales"].sum()
print(sales_by_type)
# Get proportion for each type
sales_propn_by_type = sales_by_type / sum(sales_by_type)
print(sales_propn_by_type)

>> Output
type
A    2.337e+08
B    2.318e+07
Name: weekly_sales, dtype: float64

type
A    0.91
B    0.09
Name: weekly_sales, dtype: float64
```

>**Example3 - Multiple groupings**
```python
# From previous step
sales_by_type = sales.groupby("type")["weekly_sales"].sum()

# Group by type and is_holiday; calc total weekly sales
sales_by_type_is_holiday = sales.groupby(["type","is_holiday"])["weekly_sales"].sum()
print(sales_by_type_is_holiday)

>> Output
type  is_holiday
A     False         2.337e+08
      True          2.360e+04
B     False         2.318e+07
      True          1.621e+03
Name: weekly_sales, dtype: float64
```
>**Example 4 - Multiple Group Summaries**
```python
# Import numpy with the alias np
import numpy as np

# For each store type, aggregate weekly_sales: get min, max, mean, and median
sales_stats = sales.groupby("type")["weekly_sales"].agg([np.min, np.max, np.mean, np.median])

# Print sales_stats
print(sales_stats)

# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean, and median
unemp_fuel_stats = sales.groupby("type")[["unemployment","fuel_price_usd_per_l"]].agg([np.min, np.max, np.mean, np.median])

# Print unemp_fuel_stats
print(unemp_fuel_stats)

>> Output

        amin       amax       mean    median
type                                        
A    -1098.0  293966.05  23674.667  11943.92
B     -798.0  232558.51  25696.678  13336.08
     unemployment                      fuel_price_usd_per_l                     
             amin   amax   mean median                 amin   amax   mean median
type                                                                            
A           3.879  8.992  7.973  8.067                0.664  1.107  0.745  0.735
B           7.170  9.765  9.279  9.199                0.760  1.108  0.806  0.803
```

## Pivot Tables - Another way of calculating grouped stats
>**Group by to Pivot tables**
```python
dogs.groupby("color")["weight_kg"].mean()
#Using Pivot tables
dogs.pivot_table(values="weight_kg", index="color") #By Default it calculates the mean
#aggfunc argument calucltaes other stas
dogs.pivot_table(values="weight_kg", index="color", aggfunc = np.median)

#Multiple summary stats. pass list of functions as list
dogs.pivot_table(values="weight_kg", index="color", aggfunc = [np.mean, np.median])
```
>**Pivot on two variables**
```python
dogs.groupby(["color","breed"])["weight_kg"].mean()

#Using Pivot
dogs.pivot_table(values="weight_kg", index="color", columns="breed") #To group by two variables, pass second variable in the column argument
#This will result in NaN if the value of the combination doesnt exist. We can fill nas to 0 
dogs.pivot_table(values="weight_kg", index="color", columns="breed", fill_value = 0)

#To get group total stats, set margins = True. The last rwo and last value will be summary of totals. 
#Not including missing values those are filled with zeros
dogs.pivot_table(values="weight_kg", index="color", columns="breed", fill_value = 0, margins=True)
```
>**Example1 -  Pivoting on 1 variable**
```python
# Pivot for mean weekly_sales for each store type
mean_sales_by_type = sales.pivot_table(values="weekly_sales", index="type")

# Print mean_sales_by_type
print(mean_sales_by_type)

>> Output
      weekly_sales
type              
A        23674.667
B        25696.678

# Import NumPy as np
import numpy as np

# Pivot for mean and median weekly_sales for each store type
mean_med_sales_by_type = sales.pivot_table(values="weekly_sales", index="type", aggfunc=[np.mean, np.median])

# Print mean_med_sales_by_type
print(mean_med_sales_by_type)

>> Output
             mean       median
     weekly_sales weekly_sales
type                          
A       23674.667     11943.92
B       25696.678     13336.08


# Pivot for mean weekly_sales by store type and holiday 
mean_sales_by_type_holiday = sales.pivot_table(values="weekly_sales", index="type", columns="is_holiday")

# Print mean_sales_by_type_holiday
print(mean_sales_by_type_holiday)

>>Output
is_holiday      False     True
type                          
A           23768.584  590.045
B           25751.981  810.705
```

>**Exapmle 2 -Filling Missing Values to 0**
>
```python
# Print mean weekly_sales by department and type; fill missing values with 0
print(sales.pivot_table(values="weekly_sales", index="department", columns="type", fill_value = 0))

>> Output
type                 A           B
department                        
1            30961.725   44050.627
2            67600.159  112958.527
3            17160.003   30580.655
4            44285.399   51219.654
5            34821.011   63236.875

# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols
print(sales.pivot_table(values="weekly_sales", index="department", columns="type", fill_value = 0, margins=all))

>> Output
type                A           B        All
department                                  
1           30961.725   44050.627  32052.467
2           67600.159  112958.527  71380.023
3           17160.003   30580.655  18278.391
4           44285.399   51219.654  44863.254
5           34821.011   63236.875  37189.000
...               ...         ...        ...
96          21367.043    9528.538  20337.608
97          28471.267    5828.873  26584.401
98          12875.423     217.428  11820.590
99            379.124       0.000    379.124
All         23674.667   25696.678  23843.950

[81 rows x 3 columns]
```

# Explicit Indexes
>**Setting a column as an index**
```python
dogs_ind = dogs.set_index("name")
```
>**Removing a column as an index**
```python
dogs_ind.reset_index() #The name column is removed from index and assigned basck as a column
```

>**Dropping an index**
```python
dogs_ind.reset_index(drop=True) # Index is removed and also the name column is dropped because it was the part of the index
``` 

>**Indexes makes subsetting simpler**
```python
#without an index
dogs[dogs["name"].isin(["Bella","Stella"])]

#with index we can use .loc
dogs_ind.loc[["Bella","Stella"]]
```
>**Index values don't need to be unque**
>There can be two same values in the indexes
Subsetting on duplicate index will return multiple values

>**Multi-level index a.k.a. Hierarchical indexes**
```python
dogs_ind3 = dogs.set_index(["breed", "color"])
#The inner level of index, here, color is nested within the outer level of index
```

>**Subset Outer level index with list**
```python
dogs_ind3.loc[["Labrador","Chihuahua"]]
```

>**Subset inner levels with a list of tuples**
```python
dogs_ind3.loc[[("Labrador", "Brown") , ("Chihuahua", "Tan")]]
```

>**Sorting based on indexes**
```python
dogs_ind3.sort_index() #By default it will sort all indexes from Outer level to inner level
```
>**You can control the sorting order by passing lists**
```python
dogs_ind3.sort_index(level=["color", "breed"], ascending=[True, False])
```

>**Example1 - Setting and removing indexes**
```python
# Look at temperatures
print(temperatures)

# Set the index of temperatures to city
temperatures_ind = temperatures.set_index("city")

# Look at temperatures_ind
print(temperatures_ind)

>>Output

             date        country  avg_temp_c
city                                         
Abidjan 2000-01-01  Côte D'Ivoire      27.293
Abidjan 2000-02-01  Côte D'Ivoire      27.685
Abidjan 2000-03-01  Côte D'Ivoire      29.061
Abidjan 2000-04-01  Côte D'Ivoire      28.162
Abidjan 2000-05-01  Côte D'Ivoire      27.547
...            ...            ...         ...
Xian    2013-05-01          China      18.979
Xian    2013-06-01          China      23.522
Xian    2013-07-01          China      25.251
Xian    2013-08-01          China      24.528
Xian    2013-09-01          China         NaN

[16500 rows x 3 columns]

# Reset the temperatures_ind index, keeping its contents
print(temperatures_ind.reset_index())

>>Output
          city       date        country  avg_temp_c
0      Abidjan 2000-01-01  Côte D'Ivoire      27.293
1      Abidjan 2000-02-01  Côte D'Ivoire      27.685
2      Abidjan 2000-03-01  Côte D'Ivoire      29.061
3      Abidjan 2000-04-01  Côte D'Ivoire      28.162
4      Abidjan 2000-05-01  Côte D'Ivoire      27.547
...        ...        ...            ...         ...
16495     Xian 2013-05-01          China      18.979
16496     Xian 2013-06-01          China      23.522
16497     Xian 2013-07-01          China      25.251
16498     Xian 2013-08-01          China      24.528
16499     Xian 2013-09-01          China         NaN

[16500 rows x 4 columns]

# Reset the temperatures_ind index, dropping its contents
print(temperatures_ind.reset_index(drop=True))

>>Output

            date        country  avg_temp_c
0     2000-01-01  Côte D'Ivoire      27.293
1     2000-02-01  Côte D'Ivoire      27.685
2     2000-03-01  Côte D'Ivoire      29.061
3     2000-04-01  Côte D'Ivoire      28.162
4     2000-05-01  Côte D'Ivoire      27.547
...          ...            ...         ...
16495 2013-05-01          China      18.979
16496 2013-06-01          China      23.522
16497 2013-07-01          China      25.251
16498 2013-08-01          China      24.528
16499 2013-09-01          China         NaN

[16500 rows x 3 columns]
```
>**Example2 - Subsetting with .loc[]**
```python
# Make a list of cities to subset on
cities = ["Moscow", "Saint Petersburg"]

# Subset temperatures using square brackets
print(temperatures[temperatures["city"].isin(cities)])

>>Output
            date              city country  avg_temp_c
10725 2000-01-01            Moscow  Russia      -7.313
10726 2000-02-01            Moscow  Russia      -3.551
10727 2000-03-01            Moscow  Russia      -1.661
10728 2000-04-01            Moscow  Russia      10.096
10729 2000-05-01            Moscow  Russia      10.357
...          ...               ...     ...         ...
13360 2013-05-01  Saint Petersburg  Russia      12.355
13361 2013-06-01  Saint Petersburg  Russia      17.185
13362 2013-07-01  Saint Petersburg  Russia      17.234
13363 2013-08-01  Saint Petersburg  Russia      17.153
13364 2013-09-01  Saint Petersburg  Russia         NaN

[330 rows x 4 columns]

# Subset temperatures_ind using .loc[]
print(temperatures_ind.loc[cities])

>>Output
                       date country  avg_temp_c
city                                           
Moscow           2000-01-01  Russia      -7.313
Moscow           2000-02-01  Russia      -3.551
Moscow           2000-03-01  Russia      -1.661
Moscow           2000-04-01  Russia      10.096
Moscow           2000-05-01  Russia      10.357
...                     ...     ...         ...
Saint Petersburg 2013-05-01  Russia      12.355
Saint Petersburg 2013-06-01  Russia      17.185
Saint Petersburg 2013-07-01  Russia      17.234
Saint Petersburg 2013-08-01  Russia      17.153
Saint Petersburg 2013-09-01  Russia         NaN

[330 rows x 3 columns]

```

>**Setting and retrieveing from multi level indexes**
```python
# Index temperatures by country & city
temperatures_ind = temperatures.set_index(["country","city"])

# List of tuples: Brazil, Rio De Janeiro & Pakistan, Lahore
rows_to_keep = [("Brazil","Rio De Janeiro"), ("Pakistan","Lahore")]

# Subset for rows to keep
print(temperatures_ind.loc[rows_to_keep])

>>Output
                              date  avg_temp_c
country  city                                 
Brazil   Rio De Janeiro 2000-01-01      25.974
         Rio De Janeiro 2000-02-01      26.699
         Rio De Janeiro 2000-03-01      26.270
         Rio De Janeiro 2000-04-01      25.750
         Rio De Janeiro 2000-05-01      24.356
...                            ...         ...
Pakistan Lahore         2013-05-01      33.457
         Lahore         2013-06-01      34.456
         Lahore         2013-07-01      33.279
         Lahore         2013-08-01      31.511
         Lahore         2013-09-01         NaN

[330 rows x 2 columns]
```
>**We can pass a single list of outer indexes but we cant pass the single list of inner indexes**

>**Exapmle - Sorting by index values**
```python
# Sort temperatures_ind by index values
print(temperatures_ind.sort_index())

>>Output
                         date  avg_temp_c
country     city                         
Afghanistan Kabul  2000-01-01       3.326
            Kabul  2000-02-01       3.454
            Kabul  2000-03-01       9.612
            Kabul  2000-04-01      17.925
            Kabul  2000-05-01      24.658
...                       ...         ...
Zimbabwe    Harare 2013-05-01      18.298
            Harare 2013-06-01      17.020
            Harare 2013-07-01      16.299
            Harare 2013-08-01      19.232
            Harare 2013-09-01         NaN

[16500 rows x 2 columns]

# Sort temperatures_ind by index values at the city level
print(temperatures_ind.sort_index(level="city"))

>>Output
                            date  avg_temp_c
country       city                          
Côte D'Ivoire Abidjan 2000-01-01      27.293
              Abidjan 2000-02-01      27.685
              Abidjan 2000-03-01      29.061
              Abidjan 2000-04-01      28.162
              Abidjan 2000-05-01      27.547
...                          ...         ...
China         Xian    2013-05-01      18.979
              Xian    2013-06-01      23.522
              Xian    2013-07-01      25.251
              Xian    2013-08-01      24.528
              Xian    2013-09-01         NaN

[16500 rows x 2 columns]

# Sort temperatures_ind by country then descending city
print(temperatures_ind.sort_index(level=["country", "city"], ascending = [True, False]))

>>Output
                         date  avg_temp_c
country     city                         
Afghanistan Kabul  2000-01-01       3.326
            Kabul  2000-02-01       3.454
            Kabul  2000-03-01       9.612
            Kabul  2000-04-01      17.925
            Kabul  2000-05-01      24.658
...                       ...         ...
Zimbabwe    Harare 2013-05-01      18.298
            Harare 2013-06-01      17.020
            Harare 2013-07-01      16.299
            Harare 2013-08-01      19.232
            Harare 2013-09-01         NaN

[16500 rows x 2 columns]
```

## Slicing and Subsetting by .loc and .iloc
>**Sort index before you slice**
```python
dogs_srt = dogs.set_index(["breed","color"]).sort_index()
```

>**Slicing the outer level index .... We specify index values with :**
```python
dogs_srt.loc["Chow Chow":"Poodle"] # Note that the final value "Poodle" is included
# It willr eturn all Breed names between "Chow Chow" and "Poodle" including the boundaries
```

>**Slicing the inner index levels with simple list doesnt work**
```python
dogs_srt.loc["Tan":"Gray"]
# This retuen empty dataFrame
```

>**Slicing with inner index levels**
```python
dogs_srt.loc[("Labrador","Brown"):("Schnauzer","Grey")]
#It will return all the records between ("Labrador","Brown") and ("Schnauzer","Grey")
```

>**Slicing Columns**
```python
dogs_srt.loc[:, "name":"height_cm"]
#Returns all the rows and columns between name and height_cm
```

>**Slicing Rows and columns at the same time**
```python
dogs_srt.loc[("Labrador","Brown"):("Schnauzer","Grey"), "name":"height_cm"]
```

>**Subsetting based on range of dates**
```python
dogs = dogs.set_index("date_of_birth").sort_index()
# Get dogs with date_of_birth between 2014-08-25 and 2016-09-16
dogs.loc["2014-08-25":"2016-09-16"]
```

>**Slicing based on partial dates**
```python
# Get dogs with date_of_birth between 2014-01-01 and 2016-12-31
dogs.loc["2014":"2016"] #We can just slice based on years
```

>**Subsetting by row/ column number using .iloc**
```python
print(dogs.iloc[2:5, 1:4]) #Slices 3rd through 5th row and 2nd through 4th column. i.e. the final values aren't included in the slice
```

>**Example1 - Slicing Index values**

> Slicing lets you select consecutive elements of an object using first:last syntax. DataFrames can be sliced by index values or by row/column number; we'll start with the first case. This involves slicing inside the .loc[] method.

**Compared to slicing lists, there are a few things to remember.**

- You can only slice an index if the index is sorted (using .sort_index()).
- To slice at the outer level, first and last can be strings.
- To slice at inner levels, first and last should be tuples.
- If you pass a single slice to .loc[], it will slice the rows.

```python

```
